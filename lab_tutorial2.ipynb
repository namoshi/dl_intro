{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/namoshi/dl_intro/blob/master/lab_tutorial2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mlggBOGoi-2Z"
   },
   "source": [
    "2.Auto Encoder\n",
    "\n",
    "AutoEncoder generally performs learning to minimize mean squared errors between input and output.\n",
    "\n",
    "Thus, the output of the AutoEncoder is the same as the input.\n",
    "\n",
    "The features of the hidden layer are applied to various tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-EX0lXxiDIiS"
   },
   "source": [
    "â€»If you want to perform learning, create a source file.\n",
    "\n",
    "Import of required library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "-Y6T4rA4DJs2",
    "outputId": "dcb43afe-f1ca-4ea0-a8ae-7667d7f1e0af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n",
      "Cuda is available\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "\n",
    "print(torch.__version__)\n",
    "if (torch.cuda.is_available):\n",
    "    print('Cuda is available')\n",
    "else:\n",
    "    print('Cuda is not avaibalbe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pGgOOQ75DSQs"
   },
   "source": [
    "Fixed seed value for random numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pTNzVjQMDSoF"
   },
   "outputs": [],
   "source": [
    "torch.cuda.manual_seed_all(100100)\n",
    "torch.manual_seed(100100)\n",
    "np.random.seed(100100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oOb2vL4cDZQg"
   },
   "source": [
    "Parameter definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Gy9eboUDcKX"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE      = 1000\n",
    "WEIGHT_DECAY    = 0.001\n",
    "LEARNING_RATE   = 0.01\n",
    "EPOCH           = 500\n",
    "NUM_WORKERS     = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yJdLI6e-DlX3"
   },
   "source": [
    "Reading dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QWlVyeNRDlf3"
   },
   "outputs": [],
   "source": [
    "mnist_train = dsets.MNIST(\".\", download=True, train=True)\n",
    "dataTrain = []\n",
    "dataTest = []\n",
    "\n",
    "\n",
    "mnist_test = dsets.MNIST(\".\", download=True, train=False)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(mnist_train)):\n",
    "    dataTrain.append(np.array(mnist_train[i][0]))\n",
    "\n",
    "\n",
    "for i in range(len(mnist_test)):\n",
    "    dataTest.append(np.array(mnist_test[i][0]))\n",
    "\n",
    "#Change shape to (N, C, H, W) by reshape.\n",
    "dataTrain = np.array(dataTrain)\n",
    "dataTrain = dataTrain.reshape(len(mnist_train), 1, 28, 28)\n",
    "dataTrain = dataTrain / 255.0\n",
    "\n",
    "dataTest = np.array(dataTest)\n",
    "dataTest = dataTest.reshape(len(mnist_test), 1, 28, 28)\n",
    "dataTest = dataTest / 255.0\n",
    "\n",
    "datasizeTrain = len(dataTrain)\n",
    "datasizeTest  = len(dataTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DWoWejkJEvEc"
   },
   "source": [
    "Define the model structure.\n",
    "\n",
    "In this example, a multi-layer perceptron having 10 units in hidden layer is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IaOpPD6REvTe"
   },
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28*1, 10)\n",
    "        self.fc2 = nn.Linear(10, 28*28*1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28*1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = x.view(BATCH_SIZE, 1, 28, 28)\n",
    "        return x\n",
    "      \n",
    "\n",
    "net = Network()\n",
    "if torch.cuda.is_available():\n",
    "    net.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Bgv6qQVFmNd"
   },
   "source": [
    "Define loss and optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y40xXZTwFmbm"
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=LEARNING_RATE, momentum=0.9, weight_decay=WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XefAQx4lFyIe"
   },
   "source": [
    "Input data into the model for each mini-batch and perform parameter update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "fturdeYaFyau",
    "outputId": "ece38459-6f85-47b6-a741-ecdf7e71630b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 iter 600\n",
      "\ttrain mean loss=0.12878508220116297\n",
      "\ttest  mean loss=0.13053371012210846\n",
      "epoch 20 iter 1200\n",
      "\ttrain mean loss=0.11127943682173888\n",
      "\ttest  mean loss=0.1127384327352047\n",
      "epoch 30 iter 1800\n",
      "\ttrain mean loss=0.09913430536786715\n",
      "\ttest  mean loss=0.09996178597211838\n",
      "epoch 40 iter 2400\n",
      "\ttrain mean loss=0.09100556795795758\n",
      "\ttest  mean loss=0.09244673997163773\n",
      "epoch 50 iter 3000\n",
      "\ttrain mean loss=0.08526805328826109\n",
      "\ttest  mean loss=0.08687684088945388\n",
      "epoch 60 iter 3600\n",
      "\ttrain mean loss=0.08139122414092223\n",
      "\ttest  mean loss=0.08223465904593467\n",
      "epoch 70 iter 4200\n",
      "\ttrain mean loss=0.0785021111369133\n",
      "\ttest  mean loss=0.07903124913573265\n",
      "epoch 80 iter 4800\n",
      "\ttrain mean loss=0.07648219838738442\n",
      "\ttest  mean loss=0.0774450421333313\n",
      "epoch 90 iter 5400\n",
      "\ttrain mean loss=0.07490664298335711\n",
      "\ttest  mean loss=0.07544931992888451\n",
      "epoch 100 iter 6000\n",
      "\ttrain mean loss=0.07385997797052066\n",
      "\ttest  mean loss=0.07424059063196183\n",
      "epoch 110 iter 6600\n",
      "\ttrain mean loss=0.07291118564705054\n",
      "\ttest  mean loss=0.07386895939707756\n",
      "epoch 120 iter 7200\n",
      "\ttrain mean loss=0.0722200658172369\n",
      "\ttest  mean loss=0.0730980820953846\n",
      "epoch 130 iter 7800\n",
      "\ttrain mean loss=0.07182466747860114\n",
      "\ttest  mean loss=0.07229145541787148\n",
      "epoch 140 iter 8400\n",
      "\ttrain mean loss=0.07116107704738776\n",
      "\ttest  mean loss=0.07219896018505097\n",
      "epoch 150 iter 9000\n",
      "\ttrain mean loss=0.07072626811762651\n",
      "\ttest  mean loss=0.07128896564245224\n",
      "epoch 160 iter 9600\n",
      "\ttrain mean loss=0.0700369435052077\n",
      "\ttest  mean loss=0.07057839706540107\n",
      "epoch 170 iter 10200\n",
      "\ttrain mean loss=0.0688434233268102\n",
      "\ttest  mean loss=0.06959996074438095\n",
      "epoch 180 iter 10800\n",
      "\ttrain mean loss=0.0680030882358551\n",
      "\ttest  mean loss=0.06862298026680946\n",
      "epoch 190 iter 11400\n",
      "\ttrain mean loss=0.0665078729391098\n",
      "\ttest  mean loss=0.06680613160133361\n",
      "epoch 200 iter 12000\n",
      "\ttrain mean loss=0.0653810237844785\n",
      "\ttest  mean loss=0.06576597169041634\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-0769119713db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0mtBatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtBatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0myBatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxBatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myBatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtBatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2255\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2256\u001b[0m         \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2257\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2258\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainLoss = []\n",
    "testLoss  = []\n",
    "\n",
    "\n",
    "for epoch in range(1, EPOCH+1):\n",
    "    if (epoch % 10 == 0):\n",
    "        print(\"epoch\", epoch, \"iter\", epoch*(datasizeTrain//BATCH_SIZE))\n",
    "\n",
    "    net.train()\n",
    "    for i in range(0, datasizeTrain, BATCH_SIZE):\n",
    "        perm = np.random.permutation(datasizeTrain)\n",
    "        xBatch = dataTrain[perm[i:i+BATCH_SIZE]]\n",
    "        tBatch = dataTrain[perm[i:i+BATCH_SIZE]]\n",
    "        if torch.cuda.is_available():\n",
    "            xBatch = torch.from_numpy(xBatch.copy()).float().to('cuda')\n",
    "            tBatch = torch.from_numpy(tBatch.copy()).float().to('cuda')\n",
    "        else:\n",
    "            xBatch = torch.from_numpy(xBatch.copy()).float()\n",
    "            tBatch = torch.from_numpy(tBatch.copy()).float()\n",
    "        optimizer.zero_grad()\n",
    "        yBatch = net(xBatch)\n",
    "        loss = criterion(yBatch, tBatch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    net.eval()\n",
    "    sumTrainLoss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, datasizeTrain, BATCH_SIZE):\n",
    "            perm = np.random.permutation(datasizeTrain)\n",
    "            xBatch = dataTrain[perm[i:i+BATCH_SIZE]]\n",
    "            tBatch = dataTrain[perm[i:i+BATCH_SIZE]]\n",
    "            if torch.cuda.is_available():\n",
    "                xBatch = torch.from_numpy(xBatch.copy()).float().to('cuda')\n",
    "                tBatch = torch.from_numpy(tBatch.copy()).float().to('cuda')\n",
    "            else:\n",
    "                xBatch = torch.from_numpy(xBatch.copy()).float()\n",
    "                tBatch = torch.from_numpy(tBatch.copy()).float()\n",
    "            yBatch = net(xBatch)\n",
    "            loss = criterion(yBatch, tBatch)\n",
    "            if torch.cuda.is_available():\n",
    "                loss.to('cpu')\n",
    "            sumTrainLoss += float(loss.data.item()) * BATCH_SIZE\n",
    "        trainLoss.append(sumTrainLoss / datasizeTrain)\n",
    "\n",
    "        sumTestLoss = 0.0\n",
    "        for i in range(0, datasizeTest, BATCH_SIZE):\n",
    "            perm = np.random.permutation(datasizeTest)\n",
    "            xBatch = dataTest[perm[i:i+BATCH_SIZE]] # (BATCH_SIZE, 1, 128, 128)\n",
    "            tBatch = dataTest[perm[i:i+BATCH_SIZE]] # (BATCH_SIZE, 1, 128, 128)\n",
    "            if torch.cuda.is_available():\n",
    "                xBatch = torch.from_numpy(xBatch.copy()).float().to('cuda')\n",
    "                tBatch = torch.from_numpy(tBatch.copy()).float().to('cuda')\n",
    "            else:\n",
    "                xBatch = torch.from_numpy(xBatch.copy()).float()\n",
    "                tBatch = torch.from_numpy(tBatch.copy()).float()\n",
    "            yBatch = net(xBatch)\n",
    "            loss = criterion(yBatch, tBatch)\n",
    "            if torch.cuda.is_available():\n",
    "                loss.to('cpu')\n",
    "            sumTestLoss += float(loss.data.item()) * BATCH_SIZE\n",
    "        testLoss.append(sumTestLoss / datasizeTest)\n",
    "\n",
    "    if (epoch % 10 == 0):\n",
    "        print(\"\\ttrain mean loss={}\".format(sumTrainLoss / datasizeTrain))\n",
    "        print(\"\\ttest  mean loss={}\".format(sumTestLoss / datasizeTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IKNhoL4UGATY"
   },
   "source": [
    "Draw the graph of training curve of loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "colab_type": "code",
    "id": "-XCJO5bnGAZ_",
    "outputId": "0c7a62fb-635b-4167-b2b6-d733a51adde1"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (500,) and (205,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-2dec989b3dc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainLoss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestLoss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2809\u001b[0m     return gca().plot(\n\u001b[1;32m   2810\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2811\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1611\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1612\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 231\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (500,) and (205,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "\n",
    "plt.plot(range(EPOCH), trainLoss)\n",
    "plt.plot(range(EPOCH), testLoss)\n",
    "plt.legend(['train loss', 'test loss'])\n",
    "plt.title('loss')\n",
    "plt.savefig(\"loss.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Esojt9NeGaFN"
   },
   "source": [
    "Plot the some output result of the network as an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "colab_type": "code",
    "id": "Xpxyulr3GaLv",
    "outputId": "7fd57a51-bdb2-44ae-fdb0-314974285d67"
   },
   "outputs": [],
   "source": [
    "result_train = np.zeros((datasizeTrain, 1, 28, 28))\n",
    "result_test = np.zeros((datasizeTest, 1, 28, 28))\n",
    "\n",
    "#Get network output for train data.\n",
    "for i in range(0, datasizeTrain, BATCH_SIZE):\n",
    "    xBatch = dataTrain[i:i+BATCH_SIZE]\n",
    "    if torch.cuda.is_available():\n",
    "        xBatch = torch.from_numpy(xBatch.copy()).float().to('cuda')\n",
    "    else:\n",
    "        xBatch = torch.from_numpy(xBatch.copy()).float()\n",
    "    re = net(xBatch)\n",
    "    if torch.cuda.is_available():\n",
    "        result_train[i:i+BATCH_SIZE] = re.to('cpu').data\n",
    "    else:\n",
    "        result_train[i:i+BATCH_SIZE] = re.data\n",
    "\n",
    "#Get network output for test data.\n",
    "for i in range(0, datasizeTest, BATCH_SIZE):\n",
    "    xBatch = dataTest[i:i+BATCH_SIZE]\n",
    "    if torch.cuda.is_available():\n",
    "        xBatch = torch.from_numpy(xBatch.copy()).float().to('cuda')\n",
    "    else:\n",
    "        xBatch = torch.from_numpy(xBatch.copy()).float()\n",
    "    re = net(xBatch)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        result_test[i:i+BATCH_SIZE] = re.to('cpu').data\n",
    "    else:\n",
    "        result_test[i:i+BATCH_SIZE] = re.data\n",
    "\n",
    "  \n",
    "#Save the image.\n",
    "#for i in range(datasizeTrain):\n",
    "#\tpic = result_train[i]\n",
    "#\tpic= pic.reshape((28,28))\n",
    "#\tio.imsave(\"./imgtrain%d.png\"%i, pic)\n",
    "\n",
    "\n",
    "#for i in range(datasizeTest):\n",
    "#\tpic = result_test[i]\n",
    "#\tpic= pic.reshape((28,28))\n",
    "#\tio.imsave(\"./imgtest%d.png\"%i, pic)\n",
    "\n",
    "\n",
    "# display the images\n",
    "#%matplotlib inline\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(2, n, i+1)\n",
    "    plt.imshow(dataTest[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    ax = plt.subplot(2, n, i+1+n)\n",
    "    plt.imshow(result_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "lab_tutorial2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
