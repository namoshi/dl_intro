{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2P76Ycwed1U9"
   },
   "source": [
    "## Fine Tuning\n",
    "\n",
    "MNISTデータ（手書き数字）のデータを学習したネットワークの結合荷重をFashonMNISTデータ（服装データ）の初期値として利用\n",
    "\n",
    "- This program was originally written by Mr. Kanda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1091,
     "status": "ok",
     "timestamp": 1597855646482,
     "user": {
      "displayName": "神田圭次郎",
      "photoUrl": "",
      "userId": "06325901568183725812"
     },
     "user_tz": -540
    },
    "id": "_bYjCV49d5TX"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "seed = 100\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1442,
     "status": "ok",
     "timestamp": 1597855646839,
     "user": {
      "displayName": "神田圭次郎",
      "photoUrl": "",
      "userId": "06325901568183725812"
     },
     "user_tz": -540
    },
    "id": "o6FDwR_2d_Pk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /home/kurita/mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "816ac0d3aa304db79c4309a72b994d08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/kurita/mnist/MNIST/raw/train-images-idx3-ubyte.gz to /home/kurita/mnist/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /home/kurita/mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7e2d90edb8e4970a2b8bb88325e7c40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/kurita/mnist/MNIST/raw/train-labels-idx1-ubyte.gz to /home/kurita/mnist/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /home/kurita/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "085b807830b34963b6e7f247c064fdba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting /home/kurita/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to /home/kurita/mnist/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /home/kurita/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27d218b8f73e421ea040e22f468f26c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/kurita/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to /home/kurita/mnist/MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kurita/anaconda3/lib/python3.8/site-packages/torchvision/datasets/mnist.py:469: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629395347/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "# Dataset : MNIST\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import torch.utils as utils\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "dataset_train_mnist = datasets.MNIST(\n",
    "    '~/mnist', \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=transform)\n",
    "dataset_test_mnist  = datasets.MNIST(\n",
    "    '~/mnist', \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=transform)\n",
    "\n",
    "batch_size = 1000\n",
    "\n",
    "dataloader_train_mnist = utils.data.DataLoader(dataset_train_mnist,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=4)\n",
    "dataloader_test_mnist  = utils.data.DataLoader(dataset_test_mnist,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1438,
     "status": "ok",
     "timestamp": 1597855646841,
     "user": {
      "displayName": "神田圭次郎",
      "photoUrl": "",
      "userId": "06325901568183725812"
     },
     "user_tz": -540
    },
    "id": "OqYZvxazebJ9"
   },
   "outputs": [],
   "source": [
    "# Network\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import OrderedDict\n",
    "\n",
    "class Net(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Net, self).__init__()\n",
    "    self.conv = nn.Sequential(OrderedDict([\n",
    "        (\"conv1\", nn.Conv2d(1, 4, kernel_size=5)),\n",
    "        (\"relu1\", nn.ReLU()),\n",
    "        (\"pool1\", nn.MaxPool2d(2)),\n",
    "        (\"conv2\", nn.Conv2d(4, 8, kernel_size=5)),\n",
    "        (\"relu2\", nn.ReLU()),\n",
    "        (\"pool2\", nn.MaxPool2d(2)),\n",
    "    ]))\n",
    "    self.fc = nn.Sequential(OrderedDict([\n",
    "        (\"fc1\"  , nn.Linear(8 * 4 * 4, 100)),\n",
    "        (\"relu1\", nn.ReLU()),\n",
    "        (\"fc2\"  , nn.Linear(100, 10)),\n",
    "    ]))\n",
    "\n",
    "  def forward(self, x1):\n",
    "    x2 = self.conv(x1)\n",
    "    x3 = x2.view(x2.size()[0], -1)\n",
    "    y  = self.fc(x3)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 243970,
     "status": "ok",
     "timestamp": 1597855889378,
     "user": {
      "displayName": "神田圭次郎",
      "photoUrl": "",
      "userId": "06325901568183725812"
     },
     "user_tz": -540
    },
    "id": "lSooeqcKec_n",
    "outputId": "bb0d283d-3ec5-4400-c85a-35b68fb2402a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv): Sequential(\n",
      "    (conv1): Conv2d(1, 4, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (relu1): ReLU()\n",
      "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv2): Conv2d(4, 8, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (relu2): ReLU()\n",
      "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (fc1): Linear(in_features=128, out_features=100, bias=True)\n",
      "    (relu1): ReLU()\n",
      "    (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "EPOCH: 1\n",
      "  train loss: 0.5910,  train acc: 0.8283\n",
      "  test  loss: 0.5575,  test  acc: 0.8412\n",
      "EPOCH: 2\n",
      "  train loss: 0.3224,  train acc: 0.9044\n",
      "  test  loss: 0.3014,  test  acc: 0.9095\n",
      "EPOCH: 3\n",
      "  train loss: 0.2539,  train acc: 0.9242\n",
      "  test  loss: 0.2361,  test  acc: 0.9288\n",
      "EPOCH: 4\n",
      "  train loss: 0.2057,  train acc: 0.9390\n",
      "  test  loss: 0.1888,  test  acc: 0.9460\n",
      "EPOCH: 5\n",
      "  train loss: 0.1767,  train acc: 0.9456\n",
      "  test  loss: 0.1616,  test  acc: 0.9512\n",
      "EPOCH: 6\n",
      "  train loss: 0.1535,  train acc: 0.9540\n",
      "  test  loss: 0.1405,  test  acc: 0.9586\n",
      "EPOCH: 7\n",
      "  train loss: 0.1319,  train acc: 0.9603\n",
      "  test  loss: 0.1210,  test  acc: 0.9645\n",
      "EPOCH: 8\n",
      "  train loss: 0.1186,  train acc: 0.9643\n",
      "  test  loss: 0.1050,  test  acc: 0.9676\n",
      "EPOCH: 9\n",
      "  train loss: 0.1089,  train acc: 0.9668\n",
      "  test  loss: 0.0981,  test  acc: 0.9705\n",
      "EPOCH: 10\n",
      "  train loss: 0.0993,  train acc: 0.9696\n",
      "  test  loss: 0.0915,  test  acc: 0.9709\n",
      "EPOCH: 11\n",
      "  train loss: 0.0923,  train acc: 0.9721\n",
      "  test  loss: 0.0852,  test  acc: 0.9747\n",
      "EPOCH: 12\n",
      "  train loss: 0.0878,  train acc: 0.9732\n",
      "  test  loss: 0.0814,  test  acc: 0.9720\n",
      "EPOCH: 13\n",
      "  train loss: 0.0793,  train acc: 0.9760\n",
      "  test  loss: 0.0745,  test  acc: 0.9757\n",
      "EPOCH: 14\n",
      "  train loss: 0.0775,  train acc: 0.9763\n",
      "  test  loss: 0.0722,  test  acc: 0.9770\n",
      "EPOCH: 15\n",
      "  train loss: 0.0781,  train acc: 0.9757\n",
      "  test  loss: 0.0729,  test  acc: 0.9762\n",
      "EPOCH: 16\n",
      "  train loss: 0.0717,  train acc: 0.9775\n",
      "  test  loss: 0.0694,  test  acc: 0.9793\n",
      "EPOCH: 17\n",
      "  train loss: 0.0673,  train acc: 0.9787\n",
      "  test  loss: 0.0657,  test  acc: 0.9783\n",
      "EPOCH: 18\n",
      "  train loss: 0.0641,  train acc: 0.9805\n",
      "  test  loss: 0.0621,  test  acc: 0.9801\n",
      "EPOCH: 19\n",
      "  train loss: 0.0609,  train acc: 0.9812\n",
      "  test  loss: 0.0597,  test  acc: 0.9811\n",
      "EPOCH: 20\n",
      "  train loss: 0.0599,  train acc: 0.9812\n",
      "  test  loss: 0.0592,  test  acc: 0.9820\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "from torch import optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Net().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(model)\n",
    "\n",
    "for i in range(20):\n",
    "  print('EPOCH: {epo:}'.format(epo=i+1))\n",
    "\n",
    "  ### Train ###\n",
    "  model.train()\n",
    "  for x, t in dataloader_train_mnist:\n",
    "    x = x.to(device)\n",
    "    t = t.to(device)\n",
    "    model.zero_grad()\n",
    "    y = model(x)\n",
    "    loss = criterion(y, t)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "  ### Evaluate the model by using Training Samples ###\n",
    "  model.eval()\n",
    "  sum_loss = 0.0\n",
    "  sum_correct = 0\n",
    "  sum_iter = 0\n",
    "  for x, t in dataloader_train_mnist:\n",
    "    x = x.to(device)\n",
    "    t = t.to(device)\n",
    "    y = model(x)\n",
    "    loss = criterion(y, t)\n",
    "    _, predicted = y.max(1)\n",
    "    sum_loss += loss.cpu().detach().numpy()\n",
    "    sum_correct += (predicted == t).sum().item()\n",
    "    sum_iter += 1\n",
    "  print('  train loss: {loss:.4f},  train acc: {acc:.4f}'.format(loss=sum_loss/sum_iter, acc=sum_correct/(sum_iter*batch_size)))\n",
    "    \n",
    "  ### Evalueate the model by using Test Samples ###\n",
    "  model.eval()\n",
    "  sum_loss = 0.0\n",
    "  sum_correct = 0\n",
    "  sum_iter = 0\n",
    "  for x, t in dataloader_test_mnist:\n",
    "    x = x.to(device)\n",
    "    t = t.to(device)\n",
    "    y = model(x)\n",
    "    loss = criterion(y, t)\n",
    "    _, predicted = y.max(1)\n",
    "    sum_loss += loss.cpu().detach().numpy()\n",
    "    sum_correct += (predicted == t).sum().item()\n",
    "    sum_iter += 1\n",
    "  print(\"  test  loss: {loss:.4f},  test  acc: {acc:.4f}\".format(loss=sum_loss/sum_iter, acc=sum_correct/(sum_iter*batch_size)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 243963,
     "status": "ok",
     "timestamp": 1597855889379,
     "user": {
      "displayName": "神田圭次郎",
      "photoUrl": "",
      "userId": "06325901568183725812"
     },
     "user_tz": -540
    },
    "id": "rY9q-ITofMZg",
    "outputId": "6e9cf0f9-2c3f-47a1-e32a-74d7c91715dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0977,  0.0892, -0.1899, -0.1857, -0.1008],\n",
      "         [ 0.1737, -0.0633, -0.1438, -0.0632, -0.0965],\n",
      "         [-0.0323,  0.2194,  0.2388,  0.2752,  0.0975],\n",
      "         [ 0.3187,  0.3776,  0.2905,  0.0600,  0.0574],\n",
      "         [-0.0225,  0.2458,  0.1401,  0.3167,  0.1199]]], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([ 0.0040,  0.1260, -0.0220, -0.0468,  0.0221, -0.0627, -0.0960, -0.0613,\n",
      "         0.1272, -0.1395, -0.0673,  0.1380, -0.1924,  0.1084,  0.0065, -0.0804,\n",
      "         0.0113, -0.1519,  0.1435, -0.0684,  0.0955,  0.0835, -0.0648,  0.0488,\n",
      "         0.0120,  0.0997, -0.0665, -0.0005, -0.0740, -0.0075,  0.0773,  0.0325,\n",
      "         0.0312, -0.0902,  0.1036, -0.1669,  0.0570, -0.0090,  0.0493, -0.1672,\n",
      "         0.0284,  0.0149, -0.0804,  0.0767, -0.1376,  0.1068,  0.0319, -0.1873,\n",
      "        -0.1084, -0.0346, -0.0412, -0.0341, -0.0450, -0.1729,  0.0479,  0.0408,\n",
      "        -0.0107,  0.1074, -0.0660, -0.1697, -0.1611, -0.2946,  0.0864, -0.1682,\n",
      "         0.0937, -0.1178, -0.0212,  0.1112, -0.0889,  0.1370,  0.0580, -0.1077,\n",
      "        -0.1001,  0.1466,  0.1436,  0.0164, -0.0484,  0.0677,  0.0590, -0.0491,\n",
      "         0.0176, -0.1114,  0.0986,  0.1359,  0.0387, -0.1336,  0.0024, -0.2363,\n",
      "         0.2137, -0.1155, -0.1297, -0.0599, -0.0164, -0.0537,  0.0908,  0.1523,\n",
      "        -0.0178, -0.0612,  0.0641, -0.0473], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Check Parameter before Fine-Tuning\n",
    "\n",
    "print(model.conv.conv1.weight[0])\n",
    "print(model.fc.fc2.weight[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 243958,
     "status": "ok",
     "timestamp": 1597855889380,
     "user": {
      "displayName": "神田圭次郎",
      "photoUrl": "",
      "userId": "06325901568183725812"
     },
     "user_tz": -540
    },
    "id": "GLFbe-lme5se",
    "outputId": "d441d4e6-6b23-4e51-b510-b2333117b497"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv.conv1.weight False\n",
      "conv.conv1.bias False\n",
      "conv.conv2.weight False\n",
      "conv.conv2.bias False\n",
      "fc.fc1.weight True\n",
      "fc.fc1.bias True\n",
      "fc.fc2.weight True\n",
      "fc.fc2.bias True\n"
     ]
    }
   ],
   "source": [
    "# Freeze Conv Parameter\n",
    "\n",
    "for param in model.conv.parameters():\n",
    "  param.requires_grad = False\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "  print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 243951,
     "status": "ok",
     "timestamp": 1597855889380,
     "user": {
      "displayName": "神田圭次郎",
      "photoUrl": "",
      "userId": "06325901568183725812"
     },
     "user_tz": -540
    },
    "id": "f9EeNKLEeiZC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /home/kurita/fashion-mnist/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c8ae53291834934a030f8ec6973b9d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/kurita/fashion-mnist/FashionMNIST/raw/train-images-idx3-ubyte.gz to /home/kurita/fashion-mnist/FashionMNIST/raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /home/kurita/fashion-mnist/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9faf1a051e4d4006af7fec487ad48e77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/kurita/fashion-mnist/FashionMNIST/raw/train-labels-idx1-ubyte.gz to /home/kurita/fashion-mnist/FashionMNIST/raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /home/kurita/fashion-mnist/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bac8085969a4169b6c0f5375c65638c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/kurita/fashion-mnist/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to /home/kurita/fashion-mnist/FashionMNIST/raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /home/kurita/fashion-mnist/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e17e2392e864cbd9d14c4de96c6e38c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/kurita/fashion-mnist/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to /home/kurita/fashion-mnist/FashionMNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Dataset : Fashion-MNIST\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import torch.utils as utils\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "dataset_train_fmnist = datasets.FashionMNIST(\n",
    "    '~/fashion-mnist', \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=transform)\n",
    "dataset_test_fmnist  = datasets.FashionMNIST(\n",
    "    '~/fashion-mnist', \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=transform)\n",
    "\n",
    "batch_size = 1000\n",
    "\n",
    "dataloader_train_fmnist = utils.data.DataLoader(dataset_train_fmnist,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=4)\n",
    "dataloader_test_fmnist  = utils.data.DataLoader(dataset_test_fmnist,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 480906,
     "status": "ok",
     "timestamp": 1597856126343,
     "user": {
      "displayName": "神田圭次郎",
      "photoUrl": "",
      "userId": "06325901568183725812"
     },
     "user_tz": -540
    },
    "id": "2eBwNTurlMvm",
    "outputId": "dbcc0b46-5290-497b-826b-fea8cba6e617"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1\n",
      "  train loss: 0.6951,  train acc: 0.7414\n",
      "  test  loss: 0.7167,  test  acc: 0.7283\n",
      "EPOCH: 2\n",
      "  train loss: 0.6280,  train acc: 0.7662\n",
      "  test  loss: 0.6511,  test  acc: 0.7563\n",
      "EPOCH: 3\n",
      "  train loss: 0.5910,  train acc: 0.7804\n",
      "  test  loss: 0.6159,  test  acc: 0.7712\n",
      "EPOCH: 4\n",
      "  train loss: 0.5686,  train acc: 0.7901\n",
      "  test  loss: 0.5925,  test  acc: 0.7818\n",
      "EPOCH: 5\n",
      "  train loss: 0.5571,  train acc: 0.7955\n",
      "  test  loss: 0.5835,  test  acc: 0.7865\n",
      "EPOCH: 6\n",
      "  train loss: 0.5407,  train acc: 0.8030\n",
      "  test  loss: 0.5665,  test  acc: 0.7929\n",
      "EPOCH: 7\n",
      "  train loss: 0.5275,  train acc: 0.8091\n",
      "  test  loss: 0.5532,  test  acc: 0.8002\n",
      "EPOCH: 8\n",
      "  train loss: 0.5272,  train acc: 0.8026\n",
      "  test  loss: 0.5526,  test  acc: 0.7929\n",
      "EPOCH: 9\n",
      "  train loss: 0.5205,  train acc: 0.8111\n",
      "  test  loss: 0.5485,  test  acc: 0.8024\n",
      "EPOCH: 10\n",
      "  train loss: 0.5060,  train acc: 0.8146\n",
      "  test  loss: 0.5317,  test  acc: 0.8085\n",
      "EPOCH: 11\n",
      "  train loss: 0.4987,  train acc: 0.8199\n",
      "  test  loss: 0.5246,  test  acc: 0.8125\n",
      "EPOCH: 12\n",
      "  train loss: 0.5001,  train acc: 0.8153\n",
      "  test  loss: 0.5288,  test  acc: 0.8041\n",
      "EPOCH: 13\n",
      "  train loss: 0.4844,  train acc: 0.8257\n",
      "  test  loss: 0.5108,  test  acc: 0.8210\n",
      "EPOCH: 14\n",
      "  train loss: 0.4817,  train acc: 0.8267\n",
      "  test  loss: 0.5091,  test  acc: 0.8195\n",
      "EPOCH: 15\n",
      "  train loss: 0.4753,  train acc: 0.8290\n",
      "  test  loss: 0.5034,  test  acc: 0.8196\n",
      "EPOCH: 16\n",
      "  train loss: 0.4735,  train acc: 0.8281\n",
      "  test  loss: 0.5032,  test  acc: 0.8169\n",
      "EPOCH: 17\n",
      "  train loss: 0.4641,  train acc: 0.8353\n",
      "  test  loss: 0.4941,  test  acc: 0.8262\n",
      "EPOCH: 18\n",
      "  train loss: 0.4621,  train acc: 0.8341\n",
      "  test  loss: 0.4931,  test  acc: 0.8232\n",
      "EPOCH: 19\n",
      "  train loss: 0.4587,  train acc: 0.8340\n",
      "  test  loss: 0.4887,  test  acc: 0.8248\n",
      "EPOCH: 20\n",
      "  train loss: 0.4540,  train acc: 0.8378\n",
      "  test  loss: 0.4852,  test  acc: 0.8282\n"
     ]
    }
   ],
   "source": [
    "# Fine-Tuning\n",
    "\n",
    "for i in range(20):\n",
    "  print(f\"EPOCH: {i+1}\")\n",
    "\n",
    "  ### Train ###\n",
    "  model.train()\n",
    "  for x, t in dataloader_train_fmnist:\n",
    "    x = x.to(device)\n",
    "    t = t.to(device)\n",
    "    model.zero_grad()\n",
    "    y = model(x)\n",
    "    loss = criterion(y, t)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "  ### Evaluate the model by using Training Samples ###\n",
    "  model.eval()\n",
    "  sum_loss = 0.0\n",
    "  sum_correct = 0\n",
    "  sum_iter = 0\n",
    "  for x, t in dataloader_train_fmnist:\n",
    "    x = x.to(device)\n",
    "    t = t.to(device)\n",
    "    y = model(x)\n",
    "    loss = criterion(y, t)\n",
    "    _, predicted = y.max(1)\n",
    "    sum_loss += loss.cpu().detach().numpy()\n",
    "    sum_correct += (predicted == t).sum().item()\n",
    "    sum_iter += 1\n",
    "  print('  train loss: {loss:.4f},  train acc: {acc:.4f}'.format(loss=sum_loss/sum_iter, acc=sum_correct/(sum_iter*batch_size)))    \n",
    "\n",
    "  ### Evalueae the model by using Test Samples ###\n",
    "  model.eval()\n",
    "  sum_loss = 0.0\n",
    "  sum_correct = 0\n",
    "  sum_iter = 0\n",
    "  for x, t in dataloader_test_fmnist:\n",
    "    x = x.to(device)\n",
    "    t = t.to(device)\n",
    "    y = model(x)\n",
    "    loss = criterion(y, t)\n",
    "    _, predicted = y.max(1)\n",
    "    sum_loss += loss.cpu().detach().numpy()\n",
    "    sum_correct += (predicted == t).sum().item()\n",
    "    sum_iter += 1\n",
    "  print(\"  test  loss: {loss:.4f},  test  acc: {acc:.4f}\".format(loss=sum_loss/sum_iter, acc=sum_correct/(sum_iter*batch_size)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 852,
     "status": "ok",
     "timestamp": 1597856207409,
     "user": {
      "displayName": "神田圭次郎",
      "photoUrl": "",
      "userId": "06325901568183725812"
     },
     "user_tz": -540
    },
    "id": "3gDomArImUWW",
    "outputId": "efcb6f19-9208-45f9-a05e-714fb06d1435"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0987,  0.0879, -0.1839, -0.1773, -0.0885],\n",
      "         [ 0.1744, -0.0606, -0.1380, -0.0560, -0.0881],\n",
      "         [-0.0309,  0.2215,  0.2408,  0.2791,  0.1009],\n",
      "         [ 0.3180,  0.3777,  0.2913,  0.0617,  0.0589],\n",
      "         [-0.0238,  0.2449,  0.1394,  0.3165,  0.1186]]], device='cuda:0')\n",
      "tensor([ 0.0733,  0.0787, -0.1068, -0.0136,  0.0326, -0.0627,  0.2522, -0.0872,\n",
      "         0.0572, -0.0669, -0.4504,  0.1909, -0.3029,  0.2289, -0.0150, -0.0468,\n",
      "         0.0593, -0.1911,  0.0770, -0.0960,  0.0730,  0.0593, -0.0585,  0.0385,\n",
      "         0.0283,  0.1394, -0.0180, -0.0244, -0.2142,  0.0117,  0.2173, -0.0178,\n",
      "         0.0679, -0.0951,  0.1260, -0.2009,  0.0811, -0.0177,  0.0493, -0.0703,\n",
      "         0.0029,  0.0346, -0.0475,  0.0728, -0.1105,  0.2052,  0.0417, -0.1982,\n",
      "        -0.0499,  0.0131, -0.0183, -0.0523, -0.0470, -0.0475,  0.0154,  0.0383,\n",
      "        -0.0412,  0.1126, -0.0658, -0.1894, -0.1234, -0.2858,  0.0934, -0.1142,\n",
      "         0.1552, -0.0764,  0.0054,  0.0426, -0.1289,  0.1251,  0.1118, -0.1338,\n",
      "        -0.1317,  0.1115,  0.1774,  0.0915, -0.0313,  0.0677,  0.0255, -0.0505,\n",
      "         0.0720,  0.0331,  0.1109,  0.1559,  0.0579, -0.0071, -0.0067, -0.1179,\n",
      "         0.2035, -0.1316, -0.0616, -0.0023, -0.0164, -0.0685,  0.1387,  0.1809,\n",
      "         0.0734, -0.0622, -0.1959, -0.0694], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Check Parameter after Fine-Tuning\n",
    "\n",
    "print(model.conv.conv1.weight[0])\n",
    "print(model.fc.fc2.weight[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d1XlT02Lp3yi"
   },
   "source": [
    "参考<br>\n",
    "https://pytorch.org/docs/stable/notes/autograd.html"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPSudofBMhCQ+2yDBuCB94B",
   "name": "fine-tuning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
