{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2P76Ycwed1U9"
   },
   "source": [
    "## Fine Tuning\n",
    "\n",
    "MNISTデータ（手書き数字）のデータを学習したネットワークの結合荷重をFashonMNISTデータ（服装データ）の初期値として利用\n",
    "\n",
    "- This program was originally written by Mr. Kanda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1091,
     "status": "ok",
     "timestamp": 1597855646482,
     "user": {
      "displayName": "神田圭次郎",
      "photoUrl": "",
      "userId": "06325901568183725812"
     },
     "user_tz": -540
    },
    "id": "_bYjCV49d5TX"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "seed = 100\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1442,
     "status": "ok",
     "timestamp": 1597855646839,
     "user": {
      "displayName": "神田圭次郎",
      "photoUrl": "",
      "userId": "06325901568183725812"
     },
     "user_tz": -540
    },
    "id": "o6FDwR_2d_Pk"
   },
   "outputs": [],
   "source": [
    "# Dataset : MNIST\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import torch.utils as utils\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "dataset_train_mnist = datasets.MNIST(\n",
    "    '~/mnist', \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=transform)\n",
    "dataset_test_mnist  = datasets.MNIST(\n",
    "    '~/mnist', \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=transform)\n",
    "\n",
    "batch_size = 1000\n",
    "\n",
    "dataloader_train_mnist = utils.data.DataLoader(dataset_train_mnist,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=4)\n",
    "dataloader_test_mnist  = utils.data.DataLoader(dataset_test_mnist,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1438,
     "status": "ok",
     "timestamp": 1597855646841,
     "user": {
      "displayName": "神田圭次郎",
      "photoUrl": "",
      "userId": "06325901568183725812"
     },
     "user_tz": -540
    },
    "id": "OqYZvxazebJ9"
   },
   "outputs": [],
   "source": [
    "# Network\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import OrderedDict\n",
    "\n",
    "class Net(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Net, self).__init__()\n",
    "    self.conv = nn.Sequential(OrderedDict([\n",
    "        (\"conv1\", nn.Conv2d(1, 4, kernel_size=5)),\n",
    "        (\"relu1\", nn.ReLU()),\n",
    "        (\"pool1\", nn.MaxPool2d(2)),\n",
    "        (\"conv2\", nn.Conv2d(4, 8, kernel_size=5)),\n",
    "        (\"relu2\", nn.ReLU()),\n",
    "        (\"pool2\", nn.MaxPool2d(2)),\n",
    "    ]))\n",
    "    self.fc = nn.Sequential(OrderedDict([\n",
    "        (\"fc1\"  , nn.Linear(8 * 4 * 4, 100)),\n",
    "        (\"relu1\", nn.ReLU()),\n",
    "        (\"fc2\"  , nn.Linear(100, 10)),\n",
    "    ]))\n",
    "\n",
    "  def forward(self, x1):\n",
    "    x2 = self.conv(x1)\n",
    "    x3 = x2.view(x2.size()[0], -1)\n",
    "    y  = self.fc(x3)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 243970,
     "status": "ok",
     "timestamp": 1597855889378,
     "user": {
      "displayName": "神田圭次郎",
      "photoUrl": "",
      "userId": "06325901568183725812"
     },
     "user_tz": -540
    },
    "id": "lSooeqcKec_n",
    "outputId": "bb0d283d-3ec5-4400-c85a-35b68fb2402a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv): Sequential(\n",
      "    (conv1): Conv2d(1, 4, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (relu1): ReLU()\n",
      "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv2): Conv2d(4, 8, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (relu2): ReLU()\n",
      "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (fc1): Linear(in_features=128, out_features=100, bias=True)\n",
      "    (relu1): ReLU()\n",
      "    (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "EPOCH: 1\n",
      "  train loss: 0.5910,  train acc: 0.8283\n",
      "  test  loss: 0.5576,  test  acc: 0.8411\n",
      "EPOCH: 2\n",
      "  train loss: 0.3224,  train acc: 0.9044\n",
      "  test  loss: 0.3015,  test  acc: 0.9096\n",
      "EPOCH: 3\n",
      "  train loss: 0.2540,  train acc: 0.9242\n",
      "  test  loss: 0.2363,  test  acc: 0.9289\n",
      "EPOCH: 4\n",
      "  train loss: 0.2056,  train acc: 0.9392\n",
      "  test  loss: 0.1887,  test  acc: 0.9459\n",
      "EPOCH: 5\n",
      "  train loss: 0.1769,  train acc: 0.9456\n",
      "  test  loss: 0.1617,  test  acc: 0.9518\n",
      "EPOCH: 6\n",
      "  train loss: 0.1546,  train acc: 0.9533\n",
      "  test  loss: 0.1418,  test  acc: 0.9587\n",
      "EPOCH: 7\n",
      "  train loss: 0.1313,  train acc: 0.9608\n",
      "  test  loss: 0.1206,  test  acc: 0.9646\n",
      "EPOCH: 8\n",
      "  train loss: 0.1175,  train acc: 0.9645\n",
      "  test  loss: 0.1047,  test  acc: 0.9672\n",
      "EPOCH: 9\n",
      "  train loss: 0.1071,  train acc: 0.9673\n",
      "  test  loss: 0.0967,  test  acc: 0.9707\n",
      "EPOCH: 10\n",
      "  train loss: 0.0981,  train acc: 0.9698\n",
      "  test  loss: 0.0910,  test  acc: 0.9711\n",
      "EPOCH: 11\n",
      "  train loss: 0.0912,  train acc: 0.9725\n",
      "  test  loss: 0.0847,  test  acc: 0.9751\n",
      "EPOCH: 12\n",
      "  train loss: 0.0879,  train acc: 0.9731\n",
      "  test  loss: 0.0822,  test  acc: 0.9728\n",
      "EPOCH: 13\n",
      "  train loss: 0.0783,  train acc: 0.9761\n",
      "  test  loss: 0.0739,  test  acc: 0.9763\n",
      "EPOCH: 14\n",
      "  train loss: 0.0763,  train acc: 0.9767\n",
      "  test  loss: 0.0717,  test  acc: 0.9779\n",
      "EPOCH: 15\n",
      "  train loss: 0.0765,  train acc: 0.9762\n",
      "  test  loss: 0.0723,  test  acc: 0.9767\n",
      "EPOCH: 16\n",
      "  train loss: 0.0712,  train acc: 0.9778\n",
      "  test  loss: 0.0693,  test  acc: 0.9797\n",
      "EPOCH: 17\n",
      "  train loss: 0.0667,  train acc: 0.9790\n",
      "  test  loss: 0.0649,  test  acc: 0.9791\n",
      "EPOCH: 18\n",
      "  train loss: 0.0637,  train acc: 0.9808\n",
      "  test  loss: 0.0618,  test  acc: 0.9802\n",
      "EPOCH: 19\n",
      "  train loss: 0.0608,  train acc: 0.9814\n",
      "  test  loss: 0.0590,  test  acc: 0.9814\n",
      "EPOCH: 20\n",
      "  train loss: 0.0590,  train acc: 0.9818\n",
      "  test  loss: 0.0575,  test  acc: 0.9820\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "from torch import optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Net().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(model)\n",
    "\n",
    "for i in range(20):\n",
    "  print('EPOCH: {epo:}'.format(epo=i+1))\n",
    "\n",
    "  ### Train ###\n",
    "  model.train()\n",
    "  for x, t in dataloader_train_mnist:\n",
    "    x = x.to(device)\n",
    "    t = t.to(device)\n",
    "    model.zero_grad()\n",
    "    y = model(x)\n",
    "    loss = criterion(y, t)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "  ### Evaluate the model by using Training Samples ###\n",
    "  model.eval()\n",
    "  sum_loss = 0.0\n",
    "  sum_correct = 0\n",
    "  sum_iter = 0\n",
    "  for x, t in dataloader_train_mnist:\n",
    "    x = x.to(device)\n",
    "    t = t.to(device)\n",
    "    y = model(x)\n",
    "    loss = criterion(y, t)\n",
    "    _, predicted = y.max(1)\n",
    "    sum_loss += loss.cpu().detach().numpy()\n",
    "    sum_correct += (predicted == t).sum().item()\n",
    "    sum_iter += 1\n",
    "  print('  train loss: {loss:.4f},  train acc: {acc:.4f}'.format(loss=sum_loss/sum_iter, acc=sum_correct/(sum_iter*batch_size)))\n",
    "    \n",
    "  ### Evalueate the model by using Test Samples ###\n",
    "  model.eval()\n",
    "  sum_loss = 0.0\n",
    "  sum_correct = 0\n",
    "  sum_iter = 0\n",
    "  for x, t in dataloader_test_mnist:\n",
    "    x = x.to(device)\n",
    "    t = t.to(device)\n",
    "    y = model(x)\n",
    "    loss = criterion(y, t)\n",
    "    _, predicted = y.max(1)\n",
    "    sum_loss += loss.cpu().detach().numpy()\n",
    "    sum_correct += (predicted == t).sum().item()\n",
    "    sum_iter += 1\n",
    "  print(\"  test  loss: {loss:.4f},  test  acc: {acc:.4f}\".format(loss=sum_loss/sum_iter, acc=sum_correct/(sum_iter*batch_size)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 243963,
     "status": "ok",
     "timestamp": 1597855889379,
     "user": {
      "displayName": "神田圭次郎",
      "photoUrl": "",
      "userId": "06325901568183725812"
     },
     "user_tz": -540
    },
    "id": "rY9q-ITofMZg",
    "outputId": "6e9cf0f9-2c3f-47a1-e32a-74d7c91715dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.1009,  0.0867, -0.1843, -0.1771, -0.0883],\n",
      "         [ 0.1731, -0.0615, -0.1386, -0.0563, -0.0882],\n",
      "         [-0.0318,  0.2207,  0.2400,  0.2783,  0.1003],\n",
      "         [ 0.3178,  0.3772,  0.2907,  0.0611,  0.0583],\n",
      "         [-0.0234,  0.2448,  0.1392,  0.3159,  0.1181]]], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([ 0.0035,  0.1223, -0.0166, -0.0424,  0.0246, -0.0627,  0.1964, -0.0564,\n",
      "         0.1239, -0.1341, -0.0689,  0.1357, -0.1843,  0.1066,  0.0121, -0.0744,\n",
      "         0.0197, -0.1471,  0.1408, -0.0684,  0.0951,  0.0830, -0.0679,  0.0447,\n",
      "         0.0101,  0.0915, -0.0648, -0.0244, -0.1258, -0.0107,  0.0726,  0.0292,\n",
      "         0.0286, -0.0902,  0.1043, -0.1635,  0.0574, -0.0191,  0.0493, -0.1651,\n",
      "         0.0221, -0.0388, -0.0843,  0.0767, -0.1350,  0.1062,  0.0279, -0.1889,\n",
      "        -0.1058, -0.0326, -0.0434, -0.0508, -0.0491, -0.1057,  0.0470,  0.0383,\n",
      "        -0.0109,  0.1067, -0.0658, -0.1713, -0.1601, -0.2981,  0.0854, -0.1665,\n",
      "         0.0974, -0.1156, -0.0215,  0.1081, -0.0946,  0.1364,  0.0552, -0.1192,\n",
      "        -0.1002,  0.1487,  0.1434,  0.0133, -0.0526,  0.0677,  0.0593, -0.0557,\n",
      "         0.0157, -0.1056,  0.0961,  0.1335,  0.0388, -0.1317,  0.0012, -0.2741,\n",
      "         0.2087, -0.1108, -0.1289, -0.0636, -0.0164, -0.0513,  0.1120,  0.1491,\n",
      "        -0.0104, -0.0614,  0.0660, -0.0403], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Check Parameter before Fine-Tuning\n",
    "\n",
    "print(model.conv.conv1.weight[0])\n",
    "print(model.fc.fc2.weight[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 243958,
     "status": "ok",
     "timestamp": 1597855889380,
     "user": {
      "displayName": "神田圭次郎",
      "photoUrl": "",
      "userId": "06325901568183725812"
     },
     "user_tz": -540
    },
    "id": "GLFbe-lme5se",
    "outputId": "d441d4e6-6b23-4e51-b510-b2333117b497"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv.conv1.weight False\n",
      "conv.conv1.bias False\n",
      "conv.conv2.weight False\n",
      "conv.conv2.bias False\n",
      "fc.fc1.weight True\n",
      "fc.fc1.bias True\n",
      "fc.fc2.weight True\n",
      "fc.fc2.bias True\n"
     ]
    }
   ],
   "source": [
    "# Freeze Conv Parameter\n",
    "\n",
    "for param in model.conv.parameters():\n",
    "  param.requires_grad = False\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "  print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 243951,
     "status": "ok",
     "timestamp": 1597855889380,
     "user": {
      "displayName": "神田圭次郎",
      "photoUrl": "",
      "userId": "06325901568183725812"
     },
     "user_tz": -540
    },
    "id": "f9EeNKLEeiZC"
   },
   "outputs": [],
   "source": [
    "# Dataset : Fashion-MNIST\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import torch.utils as utils\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "dataset_train_fmnist = datasets.FashionMNIST(\n",
    "    '~/fashion-mnist', \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=transform)\n",
    "dataset_test_fmnist  = datasets.FashionMNIST(\n",
    "    '~/fashion-mnist', \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=transform)\n",
    "\n",
    "batch_size = 1000\n",
    "\n",
    "dataloader_train_fmnist = utils.data.DataLoader(dataset_train_fmnist,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=4)\n",
    "dataloader_test_fmnist  = utils.data.DataLoader(dataset_test_fmnist,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 480906,
     "status": "ok",
     "timestamp": 1597856126343,
     "user": {
      "displayName": "神田圭次郎",
      "photoUrl": "",
      "userId": "06325901568183725812"
     },
     "user_tz": -540
    },
    "id": "2eBwNTurlMvm",
    "outputId": "dbcc0b46-5290-497b-826b-fea8cba6e617"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1\n",
      "  train loss: 0.6808,  train acc: 0.7463\n",
      "  test  loss: 0.7037,  test  acc: 0.7376\n",
      "EPOCH: 2\n",
      "  train loss: 0.6238,  train acc: 0.7682\n",
      "  test  loss: 0.6488,  test  acc: 0.7555\n",
      "EPOCH: 3\n",
      "  train loss: 0.5850,  train acc: 0.7847\n",
      "  test  loss: 0.6106,  test  acc: 0.7735\n",
      "EPOCH: 4\n",
      "  train loss: 0.5630,  train acc: 0.7921\n",
      "  test  loss: 0.5877,  test  acc: 0.7831\n",
      "EPOCH: 5\n",
      "  train loss: 0.5498,  train acc: 0.8004\n",
      "  test  loss: 0.5772,  test  acc: 0.7889\n",
      "EPOCH: 6\n",
      "  train loss: 0.5352,  train acc: 0.8056\n",
      "  test  loss: 0.5619,  test  acc: 0.7957\n",
      "EPOCH: 7\n",
      "  train loss: 0.5220,  train acc: 0.8105\n",
      "  test  loss: 0.5498,  test  acc: 0.8025\n",
      "EPOCH: 8\n",
      "  train loss: 0.5189,  train acc: 0.8083\n",
      "  test  loss: 0.5468,  test  acc: 0.7964\n",
      "EPOCH: 9\n",
      "  train loss: 0.5133,  train acc: 0.8143\n",
      "  test  loss: 0.5431,  test  acc: 0.8030\n",
      "EPOCH: 10\n",
      "  train loss: 0.4990,  train acc: 0.8177\n",
      "  test  loss: 0.5271,  test  acc: 0.8090\n",
      "EPOCH: 11\n",
      "  train loss: 0.4927,  train acc: 0.8210\n",
      "  test  loss: 0.5204,  test  acc: 0.8129\n",
      "EPOCH: 12\n",
      "  train loss: 0.4967,  train acc: 0.8152\n",
      "  test  loss: 0.5275,  test  acc: 0.8038\n",
      "EPOCH: 13\n",
      "  train loss: 0.4774,  train acc: 0.8284\n",
      "  test  loss: 0.5060,  test  acc: 0.8203\n",
      "EPOCH: 14\n",
      "  train loss: 0.4752,  train acc: 0.8281\n",
      "  test  loss: 0.5042,  test  acc: 0.8190\n",
      "EPOCH: 15\n",
      "  train loss: 0.4668,  train acc: 0.8311\n",
      "  test  loss: 0.4972,  test  acc: 0.8216\n",
      "EPOCH: 16\n",
      "  train loss: 0.4668,  train acc: 0.8292\n",
      "  test  loss: 0.4984,  test  acc: 0.8184\n",
      "EPOCH: 17\n",
      "  train loss: 0.4570,  train acc: 0.8352\n",
      "  test  loss: 0.4889,  test  acc: 0.8267\n",
      "EPOCH: 18\n",
      "  train loss: 0.4567,  train acc: 0.8337\n",
      "  test  loss: 0.4890,  test  acc: 0.8236\n",
      "EPOCH: 19\n",
      "  train loss: 0.4531,  train acc: 0.8353\n",
      "  test  loss: 0.4837,  test  acc: 0.8267\n",
      "EPOCH: 20\n",
      "  train loss: 0.4474,  train acc: 0.8390\n",
      "  test  loss: 0.4798,  test  acc: 0.8303\n"
     ]
    }
   ],
   "source": [
    "# Fine-Tuning\n",
    "\n",
    "for i in range(20):\n",
    "  print(f\"EPOCH: {i+1}\")\n",
    "\n",
    "  ### Train ###\n",
    "  model.train()\n",
    "  for x, t in dataloader_train_fmnist:\n",
    "    x = x.to(device)\n",
    "    t = t.to(device)\n",
    "    model.zero_grad()\n",
    "    y = model(x)\n",
    "    loss = criterion(y, t)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "  ### Evaluate the model by using Training Samples ###\n",
    "  model.eval()\n",
    "  sum_loss = 0.0\n",
    "  sum_correct = 0\n",
    "  sum_iter = 0\n",
    "  for x, t in dataloader_train_fmnist:\n",
    "    x = x.to(device)\n",
    "    t = t.to(device)\n",
    "    y = model(x)\n",
    "    loss = criterion(y, t)\n",
    "    _, predicted = y.max(1)\n",
    "    sum_loss += loss.cpu().detach().numpy()\n",
    "    sum_correct += (predicted == t).sum().item()\n",
    "    sum_iter += 1\n",
    "  print('  train loss: {loss:.4f},  train acc: {acc:.4f}'.format(loss=sum_loss/sum_iter, acc=sum_correct/(sum_iter*batch_size)))    \n",
    "\n",
    "  ### Evalueae the model by using Test Samples ###\n",
    "  model.eval()\n",
    "  sum_loss = 0.0\n",
    "  sum_correct = 0\n",
    "  sum_iter = 0\n",
    "  for x, t in dataloader_test_fmnist:\n",
    "    x = x.to(device)\n",
    "    t = t.to(device)\n",
    "    y = model(x)\n",
    "    loss = criterion(y, t)\n",
    "    _, predicted = y.max(1)\n",
    "    sum_loss += loss.cpu().detach().numpy()\n",
    "    sum_correct += (predicted == t).sum().item()\n",
    "    sum_iter += 1\n",
    "  print(\"  test  loss: {loss:.4f},  test  acc: {acc:.4f}\".format(loss=sum_loss/sum_iter, acc=sum_correct/(sum_iter*batch_size)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 852,
     "status": "ok",
     "timestamp": 1597856207409,
     "user": {
      "displayName": "神田圭次郎",
      "photoUrl": "",
      "userId": "06325901568183725812"
     },
     "user_tz": -540
    },
    "id": "3gDomArImUWW",
    "outputId": "efcb6f19-9208-45f9-a05e-714fb06d1435"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0987,  0.0879, -0.1839, -0.1773, -0.0885],\n",
      "         [ 0.1744, -0.0606, -0.1380, -0.0560, -0.0881],\n",
      "         [-0.0309,  0.2215,  0.2408,  0.2791,  0.1009],\n",
      "         [ 0.3180,  0.3777,  0.2913,  0.0617,  0.0589],\n",
      "         [-0.0238,  0.2449,  0.1394,  0.3165,  0.1186]]], device='cuda:0')\n",
      "tensor([ 0.0733,  0.0787, -0.1068, -0.0136,  0.0326, -0.0627,  0.2522, -0.0872,\n",
      "         0.0572, -0.0669, -0.4504,  0.1909, -0.3029,  0.2289, -0.0150, -0.0468,\n",
      "         0.0593, -0.1911,  0.0770, -0.0960,  0.0730,  0.0593, -0.0585,  0.0385,\n",
      "         0.0283,  0.1394, -0.0180, -0.0244, -0.2142,  0.0117,  0.2173, -0.0178,\n",
      "         0.0679, -0.0951,  0.1260, -0.2009,  0.0811, -0.0177,  0.0493, -0.0703,\n",
      "         0.0029,  0.0346, -0.0475,  0.0728, -0.1105,  0.2052,  0.0417, -0.1982,\n",
      "        -0.0499,  0.0131, -0.0183, -0.0523, -0.0470, -0.0475,  0.0154,  0.0383,\n",
      "        -0.0412,  0.1126, -0.0658, -0.1894, -0.1234, -0.2858,  0.0934, -0.1142,\n",
      "         0.1552, -0.0764,  0.0054,  0.0426, -0.1289,  0.1251,  0.1118, -0.1338,\n",
      "        -0.1317,  0.1115,  0.1774,  0.0915, -0.0313,  0.0677,  0.0255, -0.0505,\n",
      "         0.0720,  0.0331,  0.1109,  0.1559,  0.0579, -0.0071, -0.0067, -0.1179,\n",
      "         0.2035, -0.1316, -0.0616, -0.0023, -0.0164, -0.0685,  0.1387,  0.1809,\n",
      "         0.0734, -0.0622, -0.1959, -0.0694], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Check Parameter after Fine-Tuning\n",
    "\n",
    "print(model.conv.conv1.weight[0])\n",
    "print(model.fc.fc2.weight[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d1XlT02Lp3yi"
   },
   "source": [
    "参考<br>\n",
    "https://pytorch.org/docs/stable/notes/autograd.html"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPSudofBMhCQ+2yDBuCB94B",
   "name": "fine-tuning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
